import unittest
import requests
import os
import sys
import time
from datetime import datetime

from sglang.srt.utils import kill_process_tree
from sglang.test.ci.ci_register import register_npu_ci
from sglang.test.ascend.test_ascend_utils import LLAMA_3_2_1B_WEIGHTS_PATH
from sglang.test.test_utils import (
    DEFAULT_TIMEOUT_FOR_SERVER_LAUNCH,
    DEFAULT_URL_FOR_TEST,
    CustomTestCase,
    popen_launch_server,
)

register_npu_ci(est_time=400, suite="nightly-1-npu-a3", nightly=True)

# é…ç½®é¡¹ï¼šä½¿ç”¨/tmpç»å¯¹è·¯å¾„ä¿ç•™æ—¥å¿—ï¼Œæ–¹ä¾¿æ’æŸ¥
LOG_DUMP_FILE = f"/tmp/test_mixed_chunk_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
CUSTOM_SERVER_WAIT_TIME = 35  # åˆ†å—é¢„å¡«å……åˆå§‹åŒ–è€—æ—¶æ›´é•¿ï¼Œå»¶é•¿å¯åŠ¨ç­‰å¾…æ—¶é—´
MODEL_TRUNK_SIZE = 2048  # Llama-3.2-1B åŸç”Ÿtrunk size
TARGET_TOKEN_COUNT = 2500  # ç›®æ ‡è¾“å…¥tokenæ•°ï¼Œè¶…è¿‡åŸç”Ÿtrunk size
CHUNK_SIZE = 1024  # åˆ†å—é¢„å¡«å……çš„æ¯ä¸ªchunkå¤§å°ï¼ˆ<2048ï¼Œä¸--chunked-prefill-sizeé…ç½®ä¸€è‡´ï¼‰

# æå‰åˆ›å»ºæ—¥å¿—æ–‡ä»¶ï¼Œè®°å½•å‚æ•°é…ç½®
with open(LOG_DUMP_FILE, "w", encoding="utf-8") as f:
    f.write(f"=== æ—¥å¿—æ–‡ä»¶åˆ›å»ºæˆåŠŸï¼Œæ—¶é—´ï¼š{datetime.now()} ===\n")
    f.write(f"=== é…ç½®å‚æ•°ï¼š--enable-mixed-chunkï¼Œ--chunked-prefill-size {CHUNK_SIZE} ===\n")

def build_long_input_text_for_token():
    """
    æ„é€ è¶³å¤Ÿtokenæ•°çš„è¾“å…¥æ–‡æœ¬ï¼ˆç¡®ä¿#new-tokenè¶…è¿‡MODEL_TRUNK_SIZEï¼‰
    æ¯ä¸ªbase_sentenceçº¦10ä¸ªtokenï¼Œé‡å¤åç¡®ä¿æ€»tokenæ•°è¾¾æ ‡
    """
    base_sentence = "This is a test sentence to generate enough tokens. "
    repeat_times = (TARGET_TOKEN_COUNT // 10) + 20
    return (base_sentence * repeat_times) + "The capital of France is"

class TestEnableMixedChunk(CustomTestCase):
    """Testcaseï¼šVerify the correctness of --enable-mixed-chunk feature (depend on --chunked-prefill-size).

    [Test Category] Parameter
    [Test Target] --enable-mixed-chunk & --chunked-prefill-size
    """

    @classmethod
    def setUpClass(cls):
        # 1. ä¿å­˜åŸå§‹IOå¥æŸ„
        cls.original_stdout_fd = os.dup(sys.stdout.fileno())
        cls.original_stderr_fd = os.dup(sys.stderr.fileno())

        # 2. æ‰“å¼€æ—¥å¿—æ–‡ä»¶å¥æŸ„
        cls.log_fd = os.open(
            LOG_DUMP_FILE,
            os.O_WRONLY | os.O_CREAT | os.O_APPEND,
            0o644
        )
        cls.log_file = open(LOG_DUMP_FILE, "a+", encoding="utf-8")

        # 3. é‡å®šå‘IOåˆ°æ—¥å¿—æ–‡ä»¶
        os.dup2(cls.log_fd, sys.stdout.fileno())
        os.dup2(cls.log_fd, sys.stderr.fileno())

        # 4. å¯åŠ¨æœåŠ¡å™¨ï¼ˆæ ¸å¿ƒï¼šæ·»åŠ  --chunked-prefill-size {CHUNK_SIZE} å¯ç”¨åˆ†å—é¢„å¡«å……ï¼‰
        other_args = [
            "--enable-mixed-chunk",
            "--attention-backend",
            "ascend",
            "--disable-cuda-graph",
            "--chunked-prefill-size", str(CHUNK_SIZE)  # å¯ç”¨åˆ†å—é¢„å¡«å……ï¼Œæ¯ä¸ªchunkæœ€å¤§1024ä¸ªtoken
        ]
        cls.process = popen_launch_server(
            LLAMA_3_2_1B_WEIGHTS_PATH,
            DEFAULT_URL_FOR_TEST,
            timeout=DEFAULT_TIMEOUT_FOR_SERVER_LAUNCH,
            other_args=other_args,
        )

        # 5. ç­‰å¾…æœåŠ¡å™¨å®Œå…¨å¯åŠ¨ï¼ˆåˆ†å—é¢„å¡«å……åˆå§‹åŒ–+æ¨¡å‹åŠ è½½ï¼Œè€—æ—¶æ›´é•¿ï¼‰
        print(f"ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨ï¼ˆ{CUSTOM_SERVER_WAIT_TIME}ç§’ï¼‰...")
        print(f"åˆ†å—é¢„å¡«å……é…ç½®ï¼š--chunked-prefill-size {CHUNK_SIZE}ï¼ˆ< æ¨¡å‹trunk size {MODEL_TRUNK_SIZE}ï¼‰")
        time.sleep(CUSTOM_SERVER_WAIT_TIME)

    @classmethod
    def tearDownClass(cls):
        # 1. ç»ˆæ­¢æœåŠ¡å™¨è¿›ç¨‹
        kill_process_tree(cls.process.pid)

        # 2. æ¢å¤IO
        os.dup2(cls.original_stdout_fd, sys.stdout.fileno())
        os.dup2(cls.original_stderr_fd, sys.stderr.fileno())

        # 3. å…³é—­æ–‡ä»¶å¥æŸ„
        os.close(cls.log_fd)
        os.close(cls.original_stdout_fd)
        os.close(cls.original_stderr_fd)
        cls.log_file.close()

        # 4. æ‰“å°å®Œæ•´æ—¥å¿—
        cls.print_full_log()

        # 5. ä¿ç•™æ—¥å¿—æ–‡ä»¶æç¤º
        print(f"\n=== æ—¥å¿—æ–‡ä»¶å·²ä¿ç•™ï¼Œè·¯å¾„ï¼š{os.path.abspath(LOG_DUMP_FILE)} ===")
        print(f"=== æŸ¥çœ‹åˆ†å—/æ··åˆæ‰¹æ¬¡æ—¥å¿—ï¼šcat {os.path.abspath(LOG_DUMP_FILE)} | grep -E 'Chunk|Prefill|Decode' ===")

    @classmethod
    def print_full_log(cls):
        """æ‰“å°å®Œæ•´æ—¥å¿—ï¼Œé‡ç‚¹å±•ç¤ºåˆ†å—é¢„å¡«å……å’Œmixed chunkç›¸å…³å†…å®¹"""
        if not os.path.exists(LOG_DUMP_FILE):
            print("\nã€æ—¥å¿—æç¤ºã€‘æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨")
            return
        
        print("\n" + "="*80)
        print(f"å®Œæ•´æ—¥å¿—ï¼ˆå«åˆ†å—é¢„å¡«å……/{CHUNK_SIZE} & mixed chunk å†…å®¹ï¼‰ï¼š")
        print("="*80)
        with open(LOG_DUMP_FILE, "r", encoding="utf-8", errors="ignore") as f:
            full_log = f.read()
            if len(full_log) <= 12000:
                print(full_log)
            else:
                print(f"ã€æ—¥å¿—è¿‡é•¿ï¼ˆ{len(full_log)}å­—ç¬¦ï¼‰ï¼Œå±•ç¤ºæœ€å12000å­—ç¬¦ã€‘")
                print(full_log[-12000:])
        print("="*80)
        print("æ—¥å¿—æ‰“å°å®Œæ¯•")

    def read_log_file(self):
        """è¯»å–æ—¥å¿—æ–‡ä»¶å†…å®¹"""
        if not os.path.exists(LOG_DUMP_FILE):
            return ""
        
        with open(LOG_DUMP_FILE, "r", encoding="utf-8", errors="ignore") as f:
            return f.read()

    def test_enable_mixed_chunk(self):
        # éªŒè¯1ï¼šhealth_generate API å¯ç”¨æ€§
        health_response = requests.get(f"{DEFAULT_URL_FOR_TEST}/health_generate")
        self.assertEqual(
            health_response.status_code, 200,
            f"health_generate API å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{health_response.status_code}"
        )

        # éªŒè¯2ï¼šè¶…é•¿tokenè¾“å…¥è°ƒç”¨/generateæ¥å£
        long_input_text = build_long_input_text_for_token()
        print(f"\næ„é€ è¾“å…¥å­—ç¬¦é•¿åº¦ï¼š{len(long_input_text)}ï¼ˆç›®æ ‡tokenæ•°ï¼š{TARGET_TOKEN_COUNT}ï¼Œåˆ†å—å¤§å°ï¼š{CHUNK_SIZE}ï¼‰")
        
        generate_response = requests.post(
            f"{DEFAULT_URL_FOR_TEST}/generate",
            json={
                "text": long_input_text,
                "sampling_params": {
                    "temperature": 0,
                    "max_new_tokens": 32,
                },
            },
            timeout=70  # åˆ†å—å¤„ç†è€—æ—¶æ›´é•¿ï¼Œå»¶é•¿è¯·æ±‚è¶…æ—¶
        )

        # éªŒè¯2.1ï¼š/generate æ¥å£çŠ¶æ€ç 
        self.assertEqual(
            generate_response.status_code, 200,
            f"/generate æ¥å£å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{generate_response.status_code}"
        )

        # éªŒè¯2.2ï¼šè¿”å›ç»“æœåŒ…å«Paris
        self.assertIn(
            "Paris", generate_response.text,
            f"/generate æœªè¿”å›Parisï¼Œé¢„è§ˆï¼š{generate_response.text[:1000]}"
        )

        # éªŒè¯3ï¼šserver_info ç¡®è®¤å‚æ•°é…ç½®æ­£ç¡®
        server_info_response = requests.get(f"{DEFAULT_URL_FOR_TEST}/server_info")
        self.assertEqual(server_info_response.status_code, 200)
        server_info_json = server_info_response.json()

        self.assertEqual(
            server_info_json.get("enable_mixed_chunk"), True,
            f"enable_mixed_chunk æœªå¼€å¯ï¼Œå½“å‰å€¼ï¼š{server_info_json.get('enable_mixed_chunk')}"
        )

        # éªŒè¯3.1ï¼šé¢å¤–ç¡®è®¤ chunked_prefill_size é…ç½®ï¼ˆè‹¥æ¥å£è¿”å›è¯¥å‚æ•°ï¼‰
        if "chunked_prefill_size" in server_info_json:
            self.assertEqual(
                server_info_json.get("chunked_prefill_size"), CHUNK_SIZE,
                f"chunked_prefill_size é…ç½®ä¸åŒ¹é…ï¼Œå½“å‰å€¼ï¼š{server_info_json.get('chunked_prefill_size')}"
            )
            print(f"\nâœ… chunked_prefill_size é…ç½®éªŒè¯é€šè¿‡ï¼š{server_info_json.get('chunked_prefill_size')}")

        # å…³é”®ï¼šç­‰å¾…åˆ†å—/æ··åˆæ‰¹æ¬¡æ—¥å¿—å†™å…¥ï¼ˆå»¶é•¿è‡³12ç§’ï¼‰
        print("\nç­‰å¾…æœåŠ¡ç«¯è¾“å‡ºåˆ†å—/æ··åˆæ‰¹æ¬¡æ—¥å¿—ï¼ˆ12ç§’ï¼‰...")
        time.sleep(12)

        # æ¢å¤IO
        os.dup2(self.original_stdout_fd, sys.stdout.fileno())
        os.dup2(self.original_stderr_fd, sys.stderr.fileno())

        # éªŒè¯4ï¼šæ ¸å¿ƒ - åˆ†å—é¢„å¡«å……å·²å¯ç”¨ï¼Œä¸”mixed chunkåŠŸèƒ½ç”Ÿæ•ˆ
        server_logs = self.read_log_file()

        # å®šä¹‰å…³é”®å­—
        chunked_prefill_keywords = [
            "chunked prefill",
            f"chunked-prefill-size {CHUNK_SIZE}",
            "Chunk [0-9]+/[0-9]+ prefill"
        ]
        mixed_chunk_keywords = [
            "Prefill + Decode batch",
            "Mixed chunk batch",
            "prefill and decode in the same batch"
        ]
        independent_batch_keywords = ["Prefill batch", "Decode batch"]

        # åˆ¤æ–­çŠ¶æ€
        is_chunked_activated = any(kw in server_logs for kw in chunked_prefill_keywords)
        is_mixed_activated = any(kw in server_logs for kw in mixed_chunk_keywords)
        has_independent_batch = all(kw in server_logs for kw in independent_batch_keywords)

        # è¾“å‡ºçŠ¶æ€æç¤º
        print("\n" + "-"*65)
        print("åˆ†å—é¢„å¡«å…… & Mixed Chunk åŠŸèƒ½æœ€ç»ˆéªŒè¯ç»“æœï¼š")
        print("-"*65)
        print(f"1. åˆ†å—é¢„å¡«å……å¯ç”¨çŠ¶æ€ï¼š{'âœ… å·²å¯ç”¨' if is_chunked_activated else 'âŒ æœªå¯ç”¨'}")
        print(f"2. Mixed Chunk åŠŸèƒ½ç”Ÿæ•ˆçŠ¶æ€ï¼š{'âœ… å·²ç”Ÿæ•ˆ' if is_mixed_activated else 'âŒ æœªç”Ÿæ•ˆ'}")
        print(f"3. ç‹¬ç«‹æ‰¹æ¬¡å­˜åœ¨çŠ¶æ€ï¼š{'âŒ æ— ç‹¬ç«‹æ‰¹æ¬¡' if not has_independent_batch else 'âœ… å­˜åœ¨ç‹¬ç«‹æ‰¹æ¬¡'}")
        print("-"*65)

        # æ ¸å¿ƒæ–­è¨€ï¼ˆå…ˆåˆ†å—ï¼Œåæ··åˆï¼‰
        self.assertTrue(is_chunked_activated, f"æ–­è¨€å¤±è´¥ï¼šæœªå¯ç”¨åˆ†å—é¢„å¡«å……ï¼Œæ— æ³•è§¦å‘Mixed Chunkï¼")
        self.assertTrue(is_mixed_activated, f"æ–­è¨€å¤±è´¥ï¼šåˆ†å—é¢„å¡«å……å·²å¯ç”¨ï¼Œä½†Mixed Chunkæœªç”Ÿæ•ˆï¼")
        self.assertFalse(has_independent_batch, f"æ–­è¨€å¤±è´¥ï¼šMixed Chunkå·²ç”Ÿæ•ˆï¼Œä½†ä»å­˜åœ¨ç‹¬ç«‹Prefill/Decodeæ‰¹æ¬¡ï¼")

        print("\nğŸ‰ æ‰€æœ‰æ ¸å¿ƒéªŒè¯é€šè¿‡ï¼--enable-mixed-chunk åŠŸèƒ½å®Œå…¨ç”Ÿæ•ˆï¼Œprefillå’Œdecodeåœ¨åŒä¸€ä¸ªbatchå†…æ‰§è¡Œï¼")
